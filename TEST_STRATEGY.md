# DataPilot Test Strategy

## Overview
Complete rebuild of test suite focusing on **user value**, **performance**, and **reliability**.

## Core Testing Philosophy

### ‚úÖ What We WILL Test
- **User-facing behavior** - CLI commands produce correct analysis
- **Statistical accuracy** - Mathematical computations are correct  
- **Data pipeline integrity** - Section dependencies work properly
- **Error handling** - Graceful failure with helpful messages
- **Performance characteristics** - Streaming works efficiently
- **Output formats** - Markdown/JSON/YAML are valid and complete

### ‚ùå What We WON'T Test  
- Implementation details (private methods, internal state)
- External libraries (Jest, Commander, etc.)
- Node.js built-ins (fs, path, etc.)
- Infrastructure concerns (CI, deployment)

## Test Architecture

### üìä Test Pyramid (Target: Sub-10s total execution)

```
        E2E Tests (10%)           - 2-3 tests, full CLI workflows
       ==================
      Integration Tests (20%)     - 15-20 tests, component interactions  
     ========================
    Unit Tests (70%)              - 80-100 tests, pure business logic
   ============================
```

## Test Categories

### 1. Unit Tests (70% of tests, <5s total)

**Core Statistical Functions**
```
src/analyzers/statistical/
‚îú‚îÄ‚îÄ descriptive-stats.test.ts     - mean, median, std dev accuracy
‚îú‚îÄ‚îÄ correlation-analysis.test.ts  - Pearson, Spearman calculations
‚îú‚îÄ‚îÄ distribution-tests.test.ts    - normality, outlier detection
‚îî‚îÄ‚îÄ type-detection.test.ts        - data type inference accuracy
```

**Data Processing Logic**  
```
src/parsers/
‚îú‚îÄ‚îÄ csv-detector.test.ts          - delimiter/encoding detection
‚îú‚îÄ‚îÄ csv-parser.test.ts            - parsing accuracy with edge cases
‚îî‚îÄ‚îÄ data-validator.test.ts        - validation rules and error messages
```

**Business Logic Analyzers**
```
src/analyzers/
‚îú‚îÄ‚îÄ section1-analyzer.test.ts     - metadata extraction accuracy
‚îú‚îÄ‚îÄ section2-analyzer.test.ts     - quality metrics calculation
‚îú‚îÄ‚îÄ section3-analyzer.test.ts     - EDA statistical computations
‚îú‚îÄ‚îÄ section4-analyzer.test.ts     - visualization recommendations
‚îú‚îÄ‚îÄ section5-analyzer.test.ts     - engineering insights logic
‚îî‚îÄ‚îÄ section6-analyzer.test.ts     - modeling suggestions
```

**Output Formatting**
```
src/formatters/
‚îú‚îÄ‚îÄ markdown-formatter.test.ts    - valid markdown generation
‚îú‚îÄ‚îÄ json-formatter.test.ts        - valid JSON structure
‚îî‚îÄ‚îÄ yaml-formatter.test.ts        - valid YAML structure
```

### 2. Integration Tests (20% of tests, <3s total)

**Pipeline Integration**
```
tests/integration/
‚îú‚îÄ‚îÄ section-dependencies.test.ts  - data flows between sections
‚îú‚îÄ‚îÄ configuration-loading.test.ts - config file precedence
‚îú‚îÄ‚îÄ memory-management.test.ts      - resource cleanup validation
‚îî‚îÄ‚îÄ error-propagation.test.ts     - error handling across components
```

**Multi-file Analysis**
```
tests/integration/
‚îú‚îÄ‚îÄ join-analysis.test.ts          - relationship detection accuracy
‚îî‚îÄ‚îÄ cross-file-validation.test.ts - consistency across datasets
```

### 3. E2E Tests (10% of tests, <2s total)

**CLI Workflows**
```
tests/e2e/
‚îú‚îÄ‚îÄ full-analysis.test.ts          - `datapilot all sample.csv`
‚îú‚îÄ‚îÄ output-formats.test.ts         - all format options work
‚îî‚îÄ‚îÄ error-scenarios.test.ts        - invalid files, bad args
```

## Test Data Strategy

### Golden Dataset Library
```
tests/fixtures/
‚îú‚îÄ‚îÄ canonical/
‚îÇ   ‚îú‚îÄ‚îÄ iris.csv              - 150 rows, 4 numeric, 1 categorical
‚îÇ   ‚îú‚îÄ‚îÄ sales.csv             - 1000 rows, mixed types, dates
‚îÇ   ‚îî‚îÄ‚îÄ employees.csv         - 500 rows, joins, missing values
‚îú‚îÄ‚îÄ edge-cases/
‚îÇ   ‚îú‚îÄ‚îÄ empty.csv             - completely empty
‚îÇ   ‚îú‚îÄ‚îÄ single-row.csv        - header + 1 data row
‚îÇ   ‚îú‚îÄ‚îÄ unicode.csv           - international characters
‚îÇ   ‚îú‚îÄ‚îÄ malformed.csv         - inconsistent columns
‚îÇ   ‚îî‚îÄ‚îÄ huge-simulation.csv   - programmatically generated large data
‚îî‚îÄ‚îÄ expected-outputs/
    ‚îú‚îÄ‚îÄ iris.analysis.json    - known correct analysis results
    ‚îú‚îÄ‚îÄ sales.analysis.json   - regression testing baselines
    ‚îî‚îÄ‚îÄ employees.analysis.json
```

## Test Quality Standards

### Performance Requirements
- **Unit tests**: <50ms each, <5s total
- **Integration tests**: <200ms each, <3s total  
- **E2E tests**: <1s each, <2s total
- **Total test suite**: <10s end-to-end

### Coverage Requirements
- **Line coverage**: 85%+ (meaningful coverage, not just percentage)
- **Branch coverage**: 80%+ (test decision points)
- **Function coverage**: 90%+ (test public interfaces)
- **Critical path coverage**: 100% (core analysis pipeline)

### Quality Gates
- Zero flaky tests (deterministic, repeatable)
- Zero console output during test runs
- No external dependencies (filesystem, network)
- Tests pass in any order (no interdependencies)

## Mocking Strategy

### What to Mock
- **File System**: Use in-memory strings instead of real files
- **Large Datasets**: Generate small synthetic data with same statistical properties
- **External Libraries**: Mock only at boundaries (hyparquet, exceljs)
- **System Resources**: Mock memory/performance monitoring

### What NOT to Mock
- **Core Business Logic**: Test actual statistical calculations
- **Standard Library**: Don't mock Math, Array methods, etc.
- **Internal Dependencies**: Test real component interactions

## Implementation Plan

### Phase 1: Foundation (Week 1)
1. Create test fixtures with golden datasets
2. Set up Jest configuration with proper thresholds
3. Build core unit tests for statistical functions
4. Implement fast CSV parsing tests

### Phase 2: Business Logic (Week 2)  
1. Test each section analyzer in isolation
2. Validate statistical accuracy with known datasets
3. Test error handling and edge cases
4. Build formatter tests for all output types

### Phase 3: Integration (Week 3)
1. Test section dependencies and data flow
2. Validate configuration system
3. Test memory management and cleanup
4. Build multi-file analysis tests

### Phase 4: E2E & Polish (Week 4)
1. Build CLI workflow tests
2. Performance optimization and validation
3. Documentation and examples
4. CI/CD integration with proper gates

## Success Metrics

### Quantitative
- Test execution time: <10s total
- Coverage: 85%+ lines, 80%+ branches  
- Zero flaky tests over 100 runs
- CI passes 99%+ of the time

### Qualitative  
- Tests are readable and maintainable
- New features can be tested easily
- Debugging is straightforward when tests fail
- Confidence in refactoring and changes

## Technology Stack

### Testing Framework
- **Jest**: Test runner and assertion library
- **@types/jest**: TypeScript support
- **jest-circus**: Modern test runner
- **fast-check**: Property-based testing for statistical functions

### Test Utilities
- **Custom matchers**: toBeCloseToStatistic(), toHaveValidMarkdown()
- **Data generators**: createSyntheticDataset(), generateCSV()
- **Mock factories**: mockFileSystem(), mockMemoryManager()

## File Organization

```
tests/
‚îú‚îÄ‚îÄ unit/                      - Mirrors src/ structure
‚îÇ   ‚îú‚îÄ‚îÄ analyzers/
‚îÇ   ‚îú‚îÄ‚îÄ parsers/
‚îÇ   ‚îú‚îÄ‚îÄ formatters/
‚îÇ   ‚îî‚îÄ‚îÄ utils/
‚îú‚îÄ‚îÄ integration/               - Cross-component tests
‚îú‚îÄ‚îÄ e2e/                       - Full CLI workflows  
‚îú‚îÄ‚îÄ fixtures/                  - Test data and golden masters
‚îú‚îÄ‚îÄ helpers/                   - Test utilities and matchers
‚îî‚îÄ‚îÄ __mocks__/                 - Module mocks
```

This strategy prioritizes **speed**, **reliability**, and **user value** while maintaining comprehensive coverage of critical functionality.